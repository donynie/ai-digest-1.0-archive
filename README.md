# 每日 AI 精选 · Daily Digest

一份**面向 AI 与科技信息的精选日报**，每日自动生成、更新，供快速浏览与回顾。

---

## 这是什么

- **日报**：聚合多日、多来源的 AI / 科技相关内容，按「YouTube」与「X 资讯」分 Tab 展示。
- **精选**：内容经筛选与整理，只保留摘要与要点，方便在几分钟内扫一眼当日或近一周重点。
- **静态站点**：纯前端 + 静态数据，无登录、无后端依赖；[GitHub Pages 访问地址](https://donynie.github.io/ai-digest-1.0-archive/)。

---

## 为什么做这份日报

随着 AI 加速，信息爆炸带来的几个痛点（你可能也有类似感受）：

1. **信息焦虑**：关注的信息源越来越多，但永远没时间看；内容堆积得越久，越不敢打开。
2. **平台推荐不可控**：想放松时被推需要深度思考的工作信息，想找 AI 内容时又被娱乐八卦拖走半小时，真正关注的信息源是否遗漏？心里没底。
3. **现有摘要工具不够好**：试过不少日报/摘要工具，常见问题是**不透明**（到底读了多少？有没有读全文？漏掉了什么？完全不知道）和**结果不稳定**（像随机抓了一些内容，筛选标准不明，对产出没有心理安全感）。

理想的预期是：像传统编辑一样，把在意的信息源都「看过」，逐条判断价值、筛选提炼，用深入浅出的方式讲清楚；每天只要扫一眼，就能判断「哪些值得深度阅读」。在理想与现实的落差下，我尝试自己实现这套编辑工作流，做成了这份每天自动生成的 AI 信息日报。

---

## 日报特色与价值

这份日报对我最大的价值是四件事：**信息透明、流程完整、分类有判断、解读有针对性**。

### 1）信息透明度：知道它到底做了什么

日报里有一个独立的「透明度」模块，会写清楚：今日一共抓取了多少条、去重与筛选后剩多少、分类依据是什么、各类信息的热度/权重如何、最终摘要与解读是怎样生成的。这样能确认这不是黑盒生成，而是真的经过筛选与整理的结果。**这一步对我非常重要。**

### 2）完整编辑流：像编辑一样逐条筛选、判断与摘要

很多日报会把抓到的数据一次性丢给大模型做筛选与摘要。但一份高质量的日报，需要抓取足够完整、数据字段足够清晰，再逐条筛选、去重、摘要与分析——这套流程很难靠一个 Prompt 一次完成。我希望它更接近传统编辑部的工作方式：**先读 → 再筛 → 再写**。完整流程带来的好处，是显著降低「幻觉式内容」，也让我更安心。

### 3）高价值的分类与判断：筛选真正重要的信息

日报不是简单堆叠信息，而是按维度做分类与价值判断，例如：行业新闻、深度观点、值得关注的新产品、可落地的 AI 协作与工作流实践。尤其是非新闻类的深度观点与 AI 实践内容，往往比全网同步传播的新闻更有价值。

### 4）专业解读：深入浅出，为「我」解读

不是简单翻译原文，而是在有限篇幅内讲清上下文，让人快速理解核心洞察。同时会回答一个问题：这些信息与我当前关注的领域或项目是否有关联？能带来什么启发？

---

技术层面：**双源**（YouTube + X 资讯）、**新版 V2 报告**（先分类再按块撰写）、**最近 7 天**可切换、**纯阅读**无配置入口，适合分享给有需要的朋友。

---

## 如何访问

- **网页**：[https://donynie.github.io/ai-digest-1.0-archive/](https://donynie.github.io/ai-digest-1.0-archive/)
- 本仓库为上述站点的源码与数据托管；每日由上游 pipeline 自动同步更新。

这份报告目前已经运转一段时间，也在持续优化。共享给有类似需求的朋友，欢迎提意见，一起把日报完善得更好。
